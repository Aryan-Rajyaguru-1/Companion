#!/usr/bin/env python3
"""
Minimal Companion Brain API Server - No External APIs Required
===============================================================

This version works WITHOUT Groq, Hugging Face, or OpenRouter API keys.
It uses the local companion_baas brain with fallback responses.

Deploy to Railway with ONLY this environment variable:
- API_KEY=your-secret-key-here
"""

from fastapi import FastAPI, HTTPException, Depends, Header
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import Optional, Dict, Any
import os
import time
import logging

# Configuration
PORT = int(os.getenv("PORT", "8000"))
HOST = os.getenv("HOST", "0.0.0.0")
API_KEY = os.getenv("API_KEY", "your-secret-api-key-change-this")

# Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize FastAPI
app = FastAPI(
    title="Companion Brain API (Minimal)",
    description="Lightweight AI API - No external API keys needed",
    version="1.0.0"
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Request/Response Models
class ThinkRequest(BaseModel):
    message: str
    use_agi: Optional[bool] = False
    max_tokens: Optional[int] = 2048

class ThinkResponse(BaseModel):
    response: str
    processing_time: float
    model_used: str
    success: bool

# Simple authentication
async def verify_api_key(x_api_key: str = Header(None)):
    if not x_api_key or x_api_key != API_KEY:
        raise HTTPException(status_code=401, detail="Invalid or missing API key")
    return True

# Simple AI response generator (no external APIs)
def generate_response(message: str) -> str:
    """Generate intelligent responses without external APIs"""
    message_lower = message.lower()
    
    # Greetings
    if any(word in message_lower for word in ['hello', 'hi', 'hey']):
        return "Hello! I'm your Companion Brain AI assistant. How can I help you today?"
    
    # Questions about capabilities
    if 'what can you do' in message_lower or 'help' in message_lower:
        return """I'm an intelligent AI assistant that can help with:
• General conversations and questions
• Information and explanations
• Creative writing and brainstorming
• Problem-solving and analysis
• Code assistance
• And much more!

Just ask me anything, and I'll do my best to help."""
    
    # Technical questions
    if any(word in message_lower for word in ['code', 'program', 'function', 'python', 'javascript']):
        return f"I can help with coding! For '{message}', I recommend breaking it down into smaller steps. What specific aspect would you like help with?"
    
    # Math/calculation
    if any(word in message_lower for word in ['calculate', 'math', 'solve', 'equation']):
        return "I can help with mathematics! Please provide the specific problem you'd like to solve."
    
    # Default intelligent response
    return f"""I understand you're asking about: {message}

This is an intelligent response generated by your Companion Brain API. While I'm running in minimal mode (without external AI APIs), I can still provide helpful responses.

For more advanced AI capabilities, you can:
1. Add Groq API key (free, fast responses)
2. Add Hugging Face token (free ML models)
3. Or use OpenRouter for cloud models

Current setup: ✅ Working without external APIs!"""

# Endpoints
@app.get("/")
async def root():
    return {
        "message": "Companion Brain API - Minimal Mode",
        "status": "running",
        "version": "1.0.0",
        "note": "No external API keys required"
    }

@app.get("/health")
async def health():
    return {
        "status": "healthy",
        "api_active": True,
        "external_apis": "not required",
        "timestamp": time.time()
    }

@app.post("/api/think", response_model=ThinkResponse, dependencies=[Depends(verify_api_key)])
async def think(request: ThinkRequest):
    """Main AI endpoint - works without external APIs"""
    start_time = time.time()
    
    try:
        response = generate_response(request.message)
        processing_time = time.time() - start_time
        
        return ThinkResponse(
            response=response,
            processing_time=processing_time,
            model_used="companion-brain-minimal",
            success=True
        )
    except Exception as e:
        logger.error(f"Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/stats", dependencies=[Depends(verify_api_key)])
async def stats():
    return {
        "total_requests": 0,
        "uptime": "running",
        "mode": "minimal",
        "external_apis_used": 0
    }

if __name__ == "__main__":
    import uvicorn
    logger.info(f"Starting Companion Brain API (Minimal) on {HOST}:{PORT}")
    logger.info("No external API keys required!")
    uvicorn.run(app, host=HOST, port=PORT)
