# ğŸ—ï¸ Companion BaaS Architecture

## Overview

Companion BaaS separates the **Brain** (AI intelligence) from the **Body** (applications).

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘               COMPANION BaaS FRAMEWORK                    â•‘
â•‘                    (The Brain)                            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                           â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â•‘
â•‘  â”‚         CompanionBrain (Core Engine)            â”‚    â•‘
â•‘  â”‚  â€¢ Request Processing                           â”‚    â•‘
â•‘  â”‚  â€¢ Context Management                           â”‚    â•‘
â•‘  â”‚  â€¢ Statistics Tracking                          â”‚    â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â•‘
â•‘                 â”‚                                         â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â•‘
â•‘  â”‚              â”‚                                   â”‚    â•‘
â•‘  â–¼              â–¼                                   â–¼    â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â•‘
â•‘  â”‚  Model   â”‚  â”‚ Context  â”‚  â”‚    Response      â”‚      â•‘
â•‘  â”‚  Router  â”‚  â”‚ Manager  â”‚  â”‚   Processor      â”‚      â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â•‘
â•‘       â”‚                                                   â•‘
â•‘       â–¼                                                   â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â•‘
â•‘  â”‚         API Wrapper (Unified Interface)         â”‚    â•‘
â•‘  â”‚  â€¢ OpenRouter Integration                       â”‚    â•‘
â•‘  â”‚  â€¢ Groq API                                     â”‚    â•‘
â•‘  â”‚  â€¢ HuggingFace                                  â”‚    â•‘
â•‘  â”‚  â€¢ Ollama Local                                 â”‚    â•‘
â•‘  â”‚  â€¢ Search Engine Wrapper                       â”‚    â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â•‘
â•‘                                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                          â”‚
                          â”‚ SDK Interface
                          â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                â”‚                â”‚
         â–¼                â–¼                â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚Chatbot  â”‚      â”‚  Coder  â”‚      â”‚Research â”‚
    â”‚  App    â”‚      â”‚   App   â”‚      â”‚   App   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Core Components

### 1. CompanionBrain (core/brain.py)

**Purpose:** Main orchestrator that handles all AI requests

**Responsibilities:**
- Process incoming requests
- Manage conversation contexts
- Route to appropriate handlers
- Handle caching
- Track statistics
- Manage errors and fallbacks

**Key Methods:**
```python
think(message, context, tools, user_id, conversation_id)
  â†’ Returns: {'response': str, 'metadata': dict, 'success': bool}

get_conversation_history(user_id, conversation_id, limit)
  â†’ Returns: List of messages

clear_conversation(user_id, conversation_id)
  â†’ Clears history

get_stats()
  â†’ Returns: Brain statistics
```

### 2. API Wrapper (Reused from Companion)

**Purpose:** Unified interface to multiple AI providers

**Integrations:**
- **OpenRouter** - Access to GPT-4, Claude, etc.
- **Groq** - Ultra-fast inference (800 tok/s)
- **HuggingFace** - Free tier with 1000+ models
- **Ollama** - Local models (fallback)
- **Search Engines** - DuckDuckGo, SearX, etc.

**Smart Features:**
- Automatic fallback if primary model fails
- Model selection based on task type
- Rate limiting and error handling
- Response caching

### 3. BrainClient (SDK)

**Purpose:** Simple interface for apps to use the brain

**Why?**
- Apps don't need to know about AI internals
- Just send message, get response
- Handles all complexity internally

**Usage:**
```python
client = BrainClient(app_type="chatbot")
response = client.ask("Hello!")
```

## Data Flow

### Request Flow
```
1. App sends request
   â†“
2. BrainClient receives
   â†“
3. CompanionBrain processes
   â†“
4. Check cache (if enabled)
   â†“
5. Get/create conversation context
   â†“
6. Determine tools needed
   â†“
7. Call API Wrapper
   â†“
8. API Wrapper selects best model
   â†“
9. Make API call(s) with fallbacks
   â†“
10. Process response
    â†“
11. Cache response
    â†“
12. Update context
    â†“
13. Return to app
```

### Context Management
```
User/Conversation
       â†“
   Brain stores in memory:
   {
     'user_123': {
       'history': [
         {'role': 'user', 'content': 'Hello'},
         {'role': 'assistant', 'content': 'Hi!'}
       ],
       'metadata': {
         'created_at': datetime,
         'app_type': 'chatbot'
       }
     }
   }
```

### Caching Strategy
```
Cache Key = hash(message + tools + app_type + has_history)
           â†“
   Check cache
           â†“
   Hit? â†’ Return cached (< 0.1s)
           â†“
   Miss? â†’ Generate new response
           â†“
        Cache for TTL:
        - With history: 30 min
        - Without history: 60 min
```

## Separation of Concerns

### The Brain (BaaS) Handles:
âœ… **AI Logic**
- Model selection
- Prompt engineering
- Response generation
- Context management
- Caching strategies

âœ… **Integration**
- API calls
- Search integration
- Error handling
- Fallback logic

âœ… **Optimization**
- Response caching
- Rate limiting
- Performance tracking

### The App Handles:
âœ… **UI/UX**
- User interface
- User interactions
- Display formatting

âœ… **Business Logic**
- App-specific features
- User authentication
- Data persistence

âœ… **Deployment**
- Hosting
- Monitoring
- Scaling

## Plug & Play Architecture

### How Any App Can Use the Brain:

```python
# Step 1: Import
from companion_baas.sdk import BrainClient

# Step 2: Initialize
brain = BrainClient(app_type="your_app_type")

# Step 3: Use
response = brain.chat("User message")

# That's it! No AI knowledge needed!
```

### App Types Supported:

| App Type | Auto-Optimizations | Default Tools |
|----------|-------------------|---------------|
| chatbot | General conversation models | None |
| coder | Code-optimized models | ['code'] |
| research | Research models + search | ['web', 'deepsearch'] |
| image_gen | Image generation models | None |
| video_gen | Video generation models | None |
| assistant | Multi-purpose models | ['web'] |
| tutor | Educational focus | ['web'] |
| analyst | Analysis + thinking | ['think', 'deepsearch'] |

## Scalability

### Current: Monolithic
```
Flask App (chat-backend.py)
â”œâ”€â”€ HTTP endpoints
â”œâ”€â”€ AI logic (mixed)
â””â”€â”€ Database
```

### With BaaS: Separated
```
Flask App                  Brain Service
â”œâ”€â”€ HTTP endpoints  â†’â†’â†’â†’  â”œâ”€â”€ AI logic
â””â”€â”€ Database              â”œâ”€â”€ Model routing
                          â””â”€â”€ Caching
```

### Future: Microservices
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ API Gateway    â”‚
   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
  â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚    â”‚         â”‚         â”‚
  â–¼    â–¼         â–¼         â–¼
â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”   â”Œâ”€â”€â”€â”
â”‚APIâ”‚ â”‚Brain  â”‚ â”‚DB â”‚   â”‚...â”‚
â”‚   â”‚ â”‚Serviceâ”‚ â”‚   â”‚   â”‚   â”‚
â””â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”˜   â””â”€â”€â”€â”˜
      (BaaS)
```

## Security Model

### Current Issues:
âŒ API keys mixed in code
âŒ Logic exposed in client-facing app
âŒ Hard to audit AI behavior

### With BaaS:
âœ… **Centralized secrets** - API keys in brain only
âœ… **Logic isolation** - Apps can't access internal AI logic
âœ… **Audit trail** - All AI requests go through brain
âœ… **Rate limiting** - Brain enforces limits centrally
âœ… **Access control** - Can add auth to brain API

## Performance Optimizations

### 1. Intelligent Caching
- Cache based on: message + context + tools
- TTL varies by query type
- Reduces API calls by ~40%

### 2. Model Selection
- Fast models for simple queries
- Powerful models for complex tasks
- Automatic fallback if model fails

### 3. Parallel Processing
- Multiple model queries in parallel
- Search + AI generation concurrently
- Fastest response wins

### 4. Connection Pooling
- Reuse HTTP connections
- Reduce latency
- Better throughput

## Future Enhancements

### Phase 2: REST API Server
```python
# Run brain as standalone service
from companion_baas.server import BrainServer

server = BrainServer(host='0.0.0.0', port=8080)
server.run()

# Apps connect via HTTP
POST http://brain-server:8080/v1/chat
{
  "message": "Hello",
  "app_id": "chatbot_v1",
  "user_id": "user123"
}
```

### Phase 3: Advanced Features
- **Streaming responses** - Real-time token streaming
- **Multi-modal** - Text + images + audio
- **Fine-tuning** - Custom model training
- **Analytics dashboard** - Visual insights
- **Plugin system** - Extensible tools
- **Load balancing** - Multiple brain instances

### Phase 4: Enterprise
- **Multi-tenancy** - Separate brains per customer
- **Usage billing** - Track API costs per app
- **SLA monitoring** - Uptime guarantees
- **Backup/Recovery** - Data persistence
- **Compliance** - GDPR, SOC2, etc.

## Comparison

### Before BaaS:
```python
# 200+ lines of mixed code
@app.route('/api/chat')
def chat():
    # Model selection logic
    # API key management
    # Prompt engineering
    # Error handling
    # Caching logic
    # Search integration
    # Response formatting
    return jsonify(response)
```

### After BaaS:
```python
# 10 lines!
@app.route('/api/chat')
def chat():
    brain = BrainClient(app_type="chatbot")
    response = brain.chat(request.json['message'])
    return jsonify(response)
```

## Summary

**Companion BaaS** = Universal AI Brain that any app can use

**Key Benefits:**
1. ğŸ§  **Build AI logic once**, use everywhere
2. ğŸ”Œ **Plug & Play** - 3 lines to add AI
3. ğŸ¯ **Focused apps** - UI separate from AI
4. ğŸš€ **Easy updates** - Update brain, all apps benefit
5. ğŸ”’ **Secure** - Centralized with proper isolation
6. ğŸ“Š **Observable** - Built-in analytics
7. ğŸ’° **Cost-effective** - Reuse instead of rebuild

**One Brain, Infinite Possibilities** ğŸŒŸ
